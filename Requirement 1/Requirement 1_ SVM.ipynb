{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN4mmvFoH+N546aHB7C3j+j"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eCiRAA80wbiI","executionInfo":{"status":"ok","timestamp":1675618248973,"user_tz":-120,"elapsed":16915,"user":{"displayName":"Mariangela Pollali","userId":"17063638695940791853"}},"outputId":"1dc14e19-857e-4f8f-b918-dd9986be50c0"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.decomposition import TruncatedSVD\n","from sklearn.svm import LinearSVC\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import f1_score\n","from sklearn import preprocessing\n","\n","import nltk\n","nltk.download('stopwords')\n","  \n","\n","import time\n","import numpy as np\n","from nltk.corpus import stopwords"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G5XO9vG4AzEN","executionInfo":{"status":"ok","timestamp":1675618248973,"user_tz":-120,"elapsed":34,"user":{"displayName":"Mariangela Pollali","userId":"17063638695940791853"}},"outputId":"1d9fa809-5796-4f03-c7c8-82b29fb8315b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"code","source":["#import stop words, data and do some pre processing\n","stop_words = set(stopwords.words('english'))\n","with open('/content/stopwords.txt') as f:\n","    for line in f:\n","        stop_words.add(line[:-1])\n","stop_words = list(stop_words)\n","#Read the csv file and change the encoding, remove tags,lower them\n","df_train = pd.read_csv('/content/drive/MyDrive/bigdata2023-exercise1-classification/train.csv', encoding='utf-8')\n","df_train['Title'] = df_train['Title'].str.encode('ascii', 'ignore').str.decode('ascii').str.lower().str.replace('<br />','')\n","df_train['Content'] = df_train['Content'].str.encode('ascii', 'ignore').str.decode('ascii').str.lower().str.replace('<br />','')\n","df_train['Label'] = df_train['Label'].str.encode('ascii', 'ignore').str.decode('ascii').str.lower().str.replace('<br />','')\n","\n","#make a new column as a combination of title & content \n","df_train['Combined']  = 3*(df_train['Title'] + ' ')  + df_train['Content']"],"metadata":{"id":"nfCzvfg4A5rF","executionInfo":{"status":"ok","timestamp":1675618257703,"user_tz":-120,"elapsed":8761,"user":{"displayName":"Mariangela Pollali","userId":"17063638695940791853"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#initializations\n","le = preprocessing.LabelEncoder()\n","y = le.fit_transform(df_train['Label'])\n","clf = LinearSVC(random_state=42, tol=1e-5)"],"metadata":{"id":"yp-bndEtA9Uk","executionInfo":{"status":"ok","timestamp":1675618257719,"user_tz":-120,"elapsed":45,"user":{"displayName":"Mariangela Pollali","userId":"17063638695940791853"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["total_time = time.time()\n","vectorizer = TfidfVectorizer(stop_words=stop_words)\n","X = vectorizer.fit_transform(df_train['Combined'])\n","\n","kfold_time = time.time()\n","kf = KFold(n_splits=5)\n","accuracy = 0\n","precision = 0\n","recall = 0\n","fmeasure = 0\n","\n","for train_index, test_index in kf.split(X):\n","    X_train, X_test = X[train_index], X[test_index]\n","    y_train, y_test = y[train_index], y[test_index]\n","\n","    clf.fit(X_train, y_train)\n","    predictions = clf.predict(X_test)\n","    \n","    accuracy += accuracy_score(y_test, predictions)\n","    precision += precision_score(y_test, predictions, average='macro')\n","    recall += recall_score(y_test, predictions, average='macro')\n","    fmeasure += f1_score(y_test, predictions, average='macro')\n","\n","accuracy /= 5\n","precision /= 5\n","recall /= 5\n","fmeasure /= 5\n","\n","print('accuracy = {}, precision = {}, recall = {}, f1-measure = {}'.format(round(accuracy, 4), round(precision,4), round(recall,4), round(fmeasure,4)))\n","print('5-fold time: {} s'.format(time.time() - kfold_time))\n","print('Total for LinearSVC: {} s'.format(time.time() - total_time))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1rtjTOJqA9mo","executionInfo":{"status":"ok","timestamp":1675618339355,"user_tz":-120,"elapsed":81679,"user":{"displayName":"Mariangela Pollali","userId":"17063638695940791853"}},"outputId":"0968f454-88c0-450d-bade-909f495a1595"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['mon'] not in stop_words.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["accuracy = 0.976, precision = 0.9745, recall = 0.973, f1-measure = 0.9737\n","5-fold time: 39.96279764175415 s\n","Total for LinearSVC: 81.61870956420898 s\n"]}]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WW3mMJ0DwBdn","executionInfo":{"status":"ok","timestamp":1675618381308,"user_tz":-120,"elapsed":41977,"user":{"displayName":"Mariangela Pollali","userId":"17063638695940791853"}},"outputId":"74159ef0-afde-4776-cf86-f5cc4bb0217a"},"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy = 0.8894, precision = 0.8826, recall = 0.8717, f1-measure = 0.8767\n","5-fold time: 25.76851773262024 s\n","Total for LinearSVC with SVD: 41.835859060287476 s\n"]}],"source":["total_time = time.time()\n","#with SVD\n","svd = TruncatedSVD(n_components=20, random_state=42)\n","X = svd.fit_transform(X)\n","\n","kfold_time = time.time()\n","kf = KFold(n_splits=5)\n","accuracy = 0\n","precision = 0\n","recall = 0\n","fmeasure = 0\n","\n","for train_index, test_index in kf.split(X):\n","    X_train, X_test = X[train_index], X[test_index]\n","    y_train, y_test = y[train_index], y[test_index]\n","\n","    clf.fit(X_train, y_train)\n","    predictions = clf.predict(X_test)\n","    \n","    accuracy += accuracy_score(y_test, predictions)\n","    precision += precision_score(y_test, predictions, average='macro')\n","    recall += recall_score(y_test, predictions, average='macro')\n","    fmeasure += f1_score(y_test, predictions, average='macro')\n","\n","accuracy /= 5\n","precision /= 5\n","recall /= 5\n","fmeasure /= 5\n","\n","print('accuracy = {}, precision = {}, recall = {}, f1-measure = {}'.format(round(accuracy, 4), round(precision,4), round(recall,4), round(fmeasure,4)))\n","print('5-fold time: {} s'.format(time.time() - kfold_time))\n","print('Total for LinearSVC with SVD: {} s'.format(time.time() - total_time))\n","\n","\n"]}]}